{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a5198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading and unzipping the IMDB reviews data\n",
    "\n",
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85f2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There’s also a train/unsup subdirectory in there, which we don’t need. Let’sdelete it:\n",
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543cdd5d",
   "metadata": {},
   "source": [
    "Next, let’s prepare a validation set by setting apart 20% of the training text files in a\n",
    " new directory, aclImdb/val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe302fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir/'val'\n",
    "train_dir = base_dir/'train'\n",
    "\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir/category)\n",
    "    files = os.listdir(train_dir/category)\n",
    "    random.Random(1327).shuffle(files)\n",
    "    num_val_samples = int(0.2*len(files))\n",
    "    val_files = files[-num_val_samples: ]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir/category/fname, \n",
    "                    val_dir/category/fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23ad18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", \n",
    "    batch_size=batch_size)\n",
    "\n",
    "validation_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size)\n",
    "\n",
    "test_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235c1997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (32,)\n",
      "datatype <dtype: 'string'>\n",
      "targets shape (32,)\n",
      "datatype (32,)\n",
      "inputs[0]: tf.Tensor(b'\"9/11,\" hosted by Robert DeNiro, presents footage from outside and inside the Twin Towers in New York, on September 11, 2001.<br /><br />Never too grisly and gory, yet powerful and moving. \"9/11\" is a real treat. Anyone not moved by this television show is immune to anything.<br /><br />5/5 stars --<br /><br />', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor([1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_dataset:\n",
    "    print('shape', inputs.shape)\n",
    "    print('datatype', inputs.dtype)\n",
    "    print('targets shape', targets.shape)\n",
    "    print('datatype', targets.shape)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17646631",
   "metadata": {},
   "source": [
    "**Preprocessing our datasets with a TextVectorization layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df767b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=20000, output_mode='multi_hot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b1b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_train_ds = train_dataset.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_1gram_train_ds = train_dataset.map(\n",
    "        lambda x, y: (text_vectorization(x), y),\n",
    "        num_parallel_calls=4\n",
    ")\n",
    "\n",
    "binary_1gram_validation_dataset = validation_dataset.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4\n",
    ")\n",
    "\n",
    "binary_1gram_test_dataset = test_dataset.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a722e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "tf.Tensor([0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for a, b in binary_1gram_test_dataset:\n",
    "    print(a[0])\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1e7eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building and compilation\n",
    "#Training and testing the binary unigram model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens, ))\n",
    "    x = layers.Dense(hidden_dim, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fbeea7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model from get_model \n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bc5776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: I was getting an error when adding callbacks. So, I decided to train the model without callbacks.\n",
    "\n",
    "\n",
    "#callbacks = ModelCheckpoint(\"binary_1gram.keras\", \n",
    "#                             save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae924b17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 33s 50ms/step - loss: 0.4063 - accuracy: 0.8246 - val_loss: 0.2843 - val_accuracy: 0.8876\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2782 - accuracy: 0.8979 - val_loss: 0.2715 - val_accuracy: 0.8980\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2451 - accuracy: 0.9130 - val_loss: 0.2801 - val_accuracy: 0.8978\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2309 - accuracy: 0.9219 - val_loss: 0.2938 - val_accuracy: 0.9008\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2195 - accuracy: 0.9258 - val_loss: 0.3046 - val_accuracy: 0.8972\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2136 - accuracy: 0.9308 - val_loss: 0.3178 - val_accuracy: 0.8996\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2054 - accuracy: 0.9355 - val_loss: 0.3296 - val_accuracy: 0.8990\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2022 - accuracy: 0.9344 - val_loss: 0.3386 - val_accuracy: 0.8988\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1956 - accuracy: 0.9359 - val_loss: 0.3460 - val_accuracy: 0.8948\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1919 - accuracy: 0.9386 - val_loss: 0.3553 - val_accuracy: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22128a09790>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model.fit(binary_1gram_train_ds.cache(),\n",
    "         validation_data=binary_1gram_validation_dataset.cache(),\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e995fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 16s 20ms/step - loss: 0.3823 - accuracy: 0.8823\n",
      "Test acc: 0.882\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(binary_1gram_test_dataset)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86518185",
   "metadata": {},
   "source": [
    "# **So, our model achieved the accuracy of 89%** \n",
    "We can imporove this applying some other techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e66012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15a430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f4d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd0c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297ef16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ad8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7854930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600fb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c1d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f58fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1db105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e925c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52109d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa07ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
