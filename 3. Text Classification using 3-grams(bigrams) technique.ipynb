{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a5198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading and unzipping the IMDB reviews data\n",
    "\n",
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85f2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There’s also a train/unsup subdirectory in there, which we don’t need. Let’sdelete it:\n",
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543cdd5d",
   "metadata": {},
   "source": [
    "Next, let’s prepare a validation set by setting apart 20% of the training text files in a\n",
    " new directory, aclImdb/val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe302fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir/'val'\n",
    "train_dir = base_dir/'train'\n",
    "\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir/category)\n",
    "    files = os.listdir(train_dir/category)\n",
    "    random.Random(1327).shuffle(files)\n",
    "    num_val_samples = int(0.2*len(files))\n",
    "    val_files = files[-num_val_samples: ]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir/category/fname, \n",
    "                    val_dir/category/fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23ad18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", \n",
    "    batch_size=batch_size)\n",
    "\n",
    "validation_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size)\n",
    "\n",
    "test_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235c1997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (32,)\n",
      "datatype <dtype: 'string'>\n",
      "targets shape (32,)\n",
      "datatype (32,)\n",
      "inputs[0]: tf.Tensor(b'As I am always looking for something new and unique, I watched this film online. I thought that it would be just another \"B\" rate movie but I was amazed at the acting by the two main characters. All of the actors in this film were very capable and well directed. The plot was wonderful and unique as well with an excellent moral to the story.<br /><br />This movie is definitely not for someone looking for a sex romp, \"Dumb and Dumber\" or blood and guts. This is a wonderfully poignant film showing some grim realities of life coupled with the kindness of the human heart and just enough frivolity to keep it interesting.<br /><br />I would prefer this movie to many \"A\" rate movies I have seen even a great number with high box office earnings.<br /><br />I highly recommend this movie.', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor([1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_dataset:\n",
    "    print('shape', inputs.shape)\n",
    "    print('datatype', inputs.dtype)\n",
    "    print('targets shape', targets.shape)\n",
    "    print('datatype', targets.shape)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17646631",
   "metadata": {},
   "source": [
    "**Preprocessing our datasets with a TextVectorization layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df767b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=20000, \n",
    "    ngrams=3,\n",
    "    output_mode='multi_hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b1b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_train_ds = train_dataset.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_3gram_train_ds = train_dataset.map(\n",
    "        lambda x, y: (text_vectorization(x), y),\n",
    "        num_parallel_calls=4\n",
    ")\n",
    "\n",
    "binary_3gram_validation_dataset = validation_dataset.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4\n",
    ")\n",
    "\n",
    "binary_3gram_test_dataset = test_dataset.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ba84f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 0. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for a, b in binary_3gram_test_dataset:\n",
    "    print(a[1])\n",
    "    print(b[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e7eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building and compilation\n",
    "#Training and testing the binary unigram model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens, ))\n",
    "    x = layers.Dense(hidden_dim, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbeea7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model from get_model \n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bc5776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks = ModelCheckpoint(\"binary_1gram.keras\", \n",
    "#                             save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae924b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 75s 116ms/step - loss: 0.3783 - accuracy: 0.8426 - val_loss: 0.2656 - val_accuracy: 0.8988\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 0.2424 - accuracy: 0.9132 - val_loss: 0.2593 - val_accuracy: 0.9030\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2067 - accuracy: 0.9320 - val_loss: 0.2743 - val_accuracy: 0.9018\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1872 - accuracy: 0.9422 - val_loss: 0.2909 - val_accuracy: 0.9008\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1744 - accuracy: 0.9466 - val_loss: 0.3107 - val_accuracy: 0.8978\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1718 - accuracy: 0.9489 - val_loss: 0.3190 - val_accuracy: 0.8984\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1675 - accuracy: 0.9525 - val_loss: 0.3361 - val_accuracy: 0.8974\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1599 - accuracy: 0.9549 - val_loss: 0.3489 - val_accuracy: 0.8988\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1491 - accuracy: 0.9563 - val_loss: 0.3594 - val_accuracy: 0.8982\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1658 - accuracy: 0.9574 - val_loss: 0.3663 - val_accuracy: 0.8992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2008be06520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model.fit(binary_3gram_train_ds.cache(),\n",
    "         validation_data=binary_3gram_validation_dataset.cache(),\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e66012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 106s 134ms/step - loss: 0.3765 - accuracy: 0.8944\n",
      "Test acc: 0.894\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(binary_3gram_test_dataset)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c205e",
   "metadata": {},
   "source": [
    "**So, our model achieved the highest accuracy of 90%** \n",
    "We can still imporove this applying some other techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15a430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f4d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd0c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297ef16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ad8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7854930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600fb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c1d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f58fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1db105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e925c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52109d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa07ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
