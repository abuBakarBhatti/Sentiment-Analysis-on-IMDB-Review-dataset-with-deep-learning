{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a5198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading and unzipping the IMDB reviews data\n",
    "\n",
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85f2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There’s also a train/unsup subdirectory in there, which we don’t need. Let’sdelete it:\n",
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543cdd5d",
   "metadata": {},
   "source": [
    "Next, let’s prepare a validation set by setting apart 20% of the training text files in a\n",
    " new directory, aclImdb/val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe302fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir/'val'\n",
    "train_dir = base_dir/'train'\n",
    "\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir/category)\n",
    "    files = os.listdir(train_dir/category)\n",
    "    random.Random(1327).shuffle(files)\n",
    "    num_val_samples = int(0.2*len(files))\n",
    "    val_files = files[-num_val_samples: ]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir/category/fname, \n",
    "                    val_dir/category/fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23ad18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", \n",
    "    batch_size=batch_size)\n",
    "\n",
    "validation_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size)\n",
    "\n",
    "test_dataset = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235c1997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (32,)\n",
      "datatype <dtype: 'string'>\n",
      "targets shape (32,)\n",
      "datatype (32,)\n",
      "inputs[0]: tf.Tensor(b'Interesting story about a soldier in a war who misses out on saving the life of a young girl from the enemy and is haunted by this event, even though he did save many other captive children. The film flashes a head and this soldier is now a teacher in a high school that is managed mostly by policemen patrolling the hallways, bathrooms and even class rooms. In other words, the High School is a prison and most of the kids pay very little attention to their teachers or principal. Dolph Lundgren,(Sam Decker) plays the soldier/school teacher and decides he is going to quit teaching and go into another field. However, the principal asks him to have a Detention Class as his last duty as a teacher. It is at this point in the film when all Hell breaks loose and the story becomes a complete BOMB. Try to enjoy it, if you decided to View IT !', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor([0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_dataset:\n",
    "    print('shape', inputs.shape)\n",
    "    print('datatype', inputs.dtype)\n",
    "    print('targets shape', targets.shape)\n",
    "    print('datatype', targets.shape)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17646631",
   "metadata": {},
   "source": [
    "**Preprocessing our datasets with a TextVectorization layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df767b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=20000, \n",
    "    ngrams=2,\n",
    "    output_mode='multi_hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b1b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_train_ds = train_dataset.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_2gram_train_ds = train_dataset.map(\n",
    "        lambda x, y: (text_vectorization(x), y),\n",
    "        num_parallel_calls=4\n",
    ")\n",
    "\n",
    "binary_2gram_validation_dataset = validation_dataset.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4\n",
    ")\n",
    "\n",
    "binary_2gram_test_dataset = test_dataset.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29ba84f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for a, b in binary_2gram_test_dataset:\n",
    "    print(a[1])\n",
    "    print(b[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e7eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building and compilation\n",
    "#Training and testing the binary unigram model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens, ))\n",
    "    x = layers.Dense(hidden_dim, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fbeea7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model from get_model \n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bc5776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks = ModelCheckpoint(\"binary_1gram.keras\", \n",
    "#                             save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae924b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.3747 - accuracy: 0.8423 - val_loss: 0.2546 - val_accuracy: 0.8988\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 8s 12ms/step - loss: 0.2374 - accuracy: 0.9157 - val_loss: 0.2605 - val_accuracy: 0.9032\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2025 - accuracy: 0.9330 - val_loss: 0.2766 - val_accuracy: 0.9044\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1863 - accuracy: 0.9446 - val_loss: 0.2950 - val_accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1802 - accuracy: 0.9484 - val_loss: 0.3139 - val_accuracy: 0.9012\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1730 - accuracy: 0.9527 - val_loss: 0.3200 - val_accuracy: 0.8990\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1630 - accuracy: 0.9550 - val_loss: 0.3409 - val_accuracy: 0.8974\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.1661 - accuracy: 0.9552 - val_loss: 0.3489 - val_accuracy: 0.8980\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1597 - accuracy: 0.9593 - val_loss: 0.3582 - val_accuracy: 0.8954\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1599 - accuracy: 0.9590 - val_loss: 0.3651 - val_accuracy: 0.8898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20a1b24ca90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model.fit(binary_2gram_train_ds.cache(),\n",
    "         validation_data=binary_2gram_validation_dataset.cache(),\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93e66012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 78s 99ms/step - loss: 0.3776 - accuracy: 0.8888\n",
      "Test acc: 0.889\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(binary_2gram_test_dataset)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c205e",
   "metadata": {},
   "source": [
    "**So, our model achieved the accuracy of 90%** \n",
    "We can still imporove this applying some other techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15a430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f4d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd0c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297ef16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ad8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7854930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600fb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c1d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f58fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1db105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e925c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52109d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa07ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
